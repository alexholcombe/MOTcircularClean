## Outline of informal talk

- TF and speed limits. Window of tracking diagram, p.5
- Demo vimeo.
- Evidence of speed and TF limit - Figure 8
- The effect of load Figure 2 p. 7 and oscillations.
- WTF kind of speed limit is this?
  - Spinzter confirms not refresh artifact (picture p. 10, results p. 11)
  - Not a limit on RFs crossed per unit time.  Off-center, data p.14
  - Diamond versus circle, no apparent effect of straight-line paths
- The dip, Figure 8
- Modeling to recover speed limits at 2 and 3 targets. VSS poster, starting with Theory
  - The modeling fail: VSS poster
  
## Feedback and after-thoughts

- Maybe you track distractors, so number of objects affects that somehow, which explains the 6->9 dip esp. if hard limit -PTG
- Bart talking about expecting it to be spatiotemporal. This is an nice abstract point to address in a review.
- Elementary motion detectors are speed-tuned, and there must be a fastest one. Why doesn't that fastest one impose a speed limit?
	- For each spatial frequency, you have one  
	- According to Gephstein et al. (2007), the elementary motion TF limit is purely a byproduct of choosing the spatiotemporal combinations optimal for estimating speed. It is not anything inherent to the way motion detectors work.
	- There is therefore no reason to expect that object tracking would be similarly limited, assuming its goal is different from estimating speed but rather to keep attention on an object. However, I could use the perceptual ecology of speeds and show that it does NOT predict the TF limit.  Different optimal model than Vul.
	- that *motion judgment and tracking are both TF-limited is only a superficial similarity*, unless someone can come up with a optimality argument for tracking being limited by low TFs
  - Want to know where the object is. Minimise positional uncertainty. How would on in principle decide on the balance between spatial and temporal uncertainty. That's assuming that you could distribute resources between spatial localisation and something like refresh rate. 
  	- One way that could happen is lengthening integration time, which gives you better spatial precision but poorer temporal precision.
  	- If objects move slowly, low refresh rate is best. Fast, higher refresh rate is best. To do an neuro-economics thing, you'd have to consider how much you can get done at 7 Hz versus higher Hz.
  - Borisyuk hypothesizes that you have a large window and calculate the average pixel within that window. 
  - It could be that there are certain spatial frequencies that are especially good, that the system is especially sensitive to. But that would only make sense if there is some process really affected by e.g. 9 objects in the circle rather than 6 (which are both very low spatial frequencies relative to the CSF), but there is not good evidence that tracking uses processes tuned to particular spatial frequencies. Those would amount to something like a global shape detector, meaning tracking of configurations rather than individual objects.
