#This file analyses anonymized data provided by "loadAnonymiseSaveData.R" in exp-specific directory
#This script expects the working directory to be "analysis"
rm(list = ls()) #Clear workspace
library(tidyverse)

dataDir<- file.path("..","dataAnonymized")
expName<- "Momo"

#Read all the Psychopy data in, from the .tsv file generated by loadAnonymiseSaveData.R in dataPreprocess directory
anonDataFile<- paste0(expName,".tsv") 
anonDataFileWithPath<-file.path(dataDir,expName,anonDataFile)
if (!file.exists(anonDataFileWithPath)) {
  message("Your anonymised datafile doesn't exist.")
}
rawData<- readr::read_tsv(anonDataFileWithPath,  show_col_types=FALSE)

#Exclusions
excludeFixationViolations = TRUE
proportnTrialsMustFixate = .6
excludeDidntReach75pct = TRUE
maxTimingBlipsToIncludeTrial = 6

#check counterbalancing of this exp
source( file.path("helpers","checkCounterbalancing.R") )
t<- checkCombosOccurEqually(rawData, c("numObjects","offset"), tolerance=.01 )
#Visually inspect trials for each combination for each subject
#table(rawData$numObjects,rawData$offset,rawData$IDnum)

# checkCombosOccurEqually(rawData, c("numObjects","numTargets","ringToQuery") )
# checkCombosOccurEqually(rawData, c("condition","leftOrRight") )
# checkCombosOccurEqually(rawData, c("condition","leftOrRight","offsetXYring0") ) #NO?
# checkCombosOccurEqually(rawData, c("numObjects","numTargets","speed") )  

datAnalyze <-rawData

datAnalyze$correct <- (datAnalyze$orderCorrect==3)
datAnalyze$correct<- as.numeric(datAnalyze$correct)
datAnalyze$chance <- 1 / datAnalyze$numObjects

#Make simpler names of variables for graphs for nicer plot labels, and make them factors
# for better plotting.
datAnalyze<- datAnalyze %>% dplyr::rename(objects = numObjects) %>% mutate(objects = as.factor(objects))
datAnalyze<- datAnalyze |> mutate(offset = as.factor(offset))

#Eyemovement exclusion zone numbers
exclusionDeg = 1 #in any direction from fixation
widthPix = 800
heightPix = 600
monitorWidth = 39.5 #cm
viewdist = 57 #cm
widthScreenDeg =  2*(atan((monitorWidth/2)/viewdist) /pi*180)
pixelsPerDegree = widthPix / widthScreenDeg
exclusionPixels = exclusionDeg * pixelsPerDegree
centralZoneWidthPix = exclusionPixels*2
centralZoneHeightPix = exclusionPixels*2 #assumes the monitor is correct aspect ratio so that pixels are square

datAnalyze$subject<- datAnalyze$IDnum
factorsForBreakdownForAnalysis <- c('objects','offset')

#If staircases work, average correct should be 0.794 in each condition
avgCorrOverall<- datAnalyze |> group_by(subject) |> summarise(mean=mean(correct),n=n())
avgCorr<- ggplot(avgCorrOverall,aes(x=subject,y=mean)) + geom_point()
#show(avgCorr)

######################################################################################
#Exclude trials where participant didn't fixate at center
##

#load table of EDF file name correspondences, from the .tsv file generated by loadAnonymiseSaveData.R in dataPreprocess directory

EDFmatchFile<- paste0(expName,"_files_guide.tsv") 
withPath<-file.path(dataDir,expName,EDFmatchFile)
if (!file.exists(withPath)) {
  message("Your EDFmatchFile doesn't exist.")
}
EDFmatchTable<- readr::read_tsv(withPath,  show_col_types=FALSE)


read_tsv(anonymisedMatchingOfDataAndEDF, file = destination_fname)

#https://github.com/alexholcombe/speed-tf-VSS14/blob/master/analyseExps/doAllAnalyses_E4ab.R
iv<-"speed"
for (iv in c("speed","tf")) { #"logTf","logSpd"
  cat('Fitting data, extracting threshes, plotting with iv=',iv)
  
  source('analyzeMakeReadyForPlot.R') #returns fitParms for each subject, psychometrics, and function calcPctCorrThisSpeed
  fitParms$iv<- iv
  #Get the plotIndividDataAndCurves function from another file
  source('individDataWithPsychometricCurves.R') 
  factorsForPlot <- tibble( colorF = "offset", colF = "objects", rowF = "subject" )
  
  #Make a few plots of psychometric functions prior to extracting threshes 
  datForThisPlot <- datAnalyze |> filter(  as.numeric(as.character(subject)) >= 27 ) |>
        filter(  as.numeric(as.character(subject)) <= 999 )
  psychometricsForThisPlot <- psychometrics |> filter( as.numeric(as.character(subject)) >=27  ) |>
    filter(  as.numeric(as.character(subject)) <= 999 )
  
  #Plot all psychometric functions
  plt<- plotIndividDataAndCurves(expName,datForThisPlot,psychometricsForThisPlot,
                           factorsForPlot,wrapOrGrid=T,xmin=0,xmax=1.5) 
  plt<-plt+facet_wrap(vars(subject))
  show(plt)
  ggsave( file.path('figs', paste0('individPlotsE',expName,'.png'))  )
  
  #Psychometric doesn't go high enough with subject= 69  objects= 8  targets= 2, which
  #from the below individual graph looks appropriate - the persom was getting 25% wrong even at low speeds
  #sub69<- datAnalyze |> filter( subject==69)
  #s69<- plotIndividDataAndCurves("subject69",sub69,
  #                         psychometricsForThisPlot |> filter(subject==69),
  #                         tibble( colorF = "targets", colF = "targets", rowF = "objects" ),
  #                         wrapOrGrid=T,xmin=0,xmax=1.5)
  
  #show(s69)
  
  thrAll<-tibble()
  source("extractMomoThreshesAndPlot.R") #provides threshes
  #Add threshes to the plots so that can see where threshold extraction failed
  write_tsv(threshes,file.path("results","threshesMomo.tsv"))
  #below is old way, saving separate threshes
  #   varName=paste("threshes_",iv,"_",expName,sep='') #combine threshes
  #   assign(varName,threshes)
  #   save(list=varName,file=paste(dataDir,varName,".Rdata",sep='')) #e.g. threshes_tf_123targets269objects.Rdata
  #   cat("Saved",varName)
}
