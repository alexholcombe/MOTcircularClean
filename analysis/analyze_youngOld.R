#This file analyses anonymized data provided by "loadAnonymiseSaveData.R" in exp-specific directory
#This script expects the working directory to be "newTraj_repo/analysis"
rm(list = ls()) #Clear workspace
library(tidyverse)

dataDir<- file.path("..","dataAnonymized")
expName<- "youngOld"

#Read all the Psychopy data in, from the .tsv file generated by loadAnonymiseSaveData.R in dataPreprocess directory
anonDataFile<- paste0(expName,".tsv") 
rawData<- readr::read_tsv( file.path(dataDir,expName,anonDataFile),  show_col_types=FALSE)
#Also need to get age and sex from somewhere.. a manual copy of the Sharepoint participant sheet with only those columns?

excludeFixationViolations = TRUE; proportnTrialsMustFixate = .6; excludeDidntReach75pct = TRUE

#check counterbalancing of this exp
source( file.path("helpers","checkCounterbalancing.R") )
t<- checkCombosOccurEqually(rawData, c("numObjects","numTargets"), tolerance=.01 )
#Visually inspect trials for each combination for each subject
#table(rawData$numObjects,rawData$numTargets,rawData$IDnum)

# checkCombosOccurEqually(rawData, c("numObjects","numTargets","ringToQuery") )
# checkCombosOccurEqually(rawData, c("condition","leftOrRight") )
# checkCombosOccurEqually(rawData, c("condition","leftOrRight","offsetXYring0") ) #NO?
# checkCombosOccurEqually(rawData, c("numObjects","numTargets","speed") )  

datAnalyze <-rawData

datAnalyze$correct <- (datAnalyze$orderCorrect==3)
datAnalyze$correct<- as.numeric(datAnalyze$correct)
datAnalyze$chance <- 1 / datAnalyze$numObjects

#Make simpler names of variables for graphs for nicer plot labels, and make them factors
# for better plotting.
datAnalyze<- datAnalyze %>% dplyr::rename(objects = numObjects) %>% mutate(objects = as.factor(objects))
datAnalyze<- datAnalyze %>% dplyr::rename(targets = numTargets) %>% mutate(targets = as.factor(targets))

#Eyemovement exclusion zone numbers
exclusionDeg = 1 #in any direction from fixation
widthPix = 800
heightPix = 600
monitorWidth = 39.5 #cm
viewdist = 57 #cm
widthScreenDeg =  2*(atan((monitorWidth/2)/viewdist) /pi*180)
pixelsPerDegree = widthPix / widthScreenDeg
exclusionPixels = exclusionDeg * pixelsPerDegree
centralZoneWidthPix = exclusionPixels*2
centralZoneHeightPix = exclusionPixels*2 #assumes the monitor is correct aspect ratio so that pixels are square

datAnalyze$subject<- datAnalyze$IDnum
factorsForBreakdownForAnalysis <- c('objects','targets')

#If staircases work, average correct should be 0.794 in each condition
avgCorrOverall<- datAnalyze |> group_by(subject) |> summarise(mean=mean(correct),n=n())
avgCorr<- ggplot(avgCorrOverall,aes(x=subject,y=mean)) + geom_point()
#subject 69 is lowest with 64% correct, not terrible

#https://github.com/alexholcombe/speed-tf-VSS14/blob/master/analyseExps/doAllAnalyses_E4ab.R
iv<-"speed"
for (iv in c("speed","tf")) { #"logTf","logSpd"
  cat('Fitting data, extracting threshes, plotting with iv=',iv)
  
  #The following file returns fitParms for each subject, psychometrics, and function calcPctCorrThisSpeed
  source('analyzeMakeReadyForPlot.R') 
  fitParms$iv<- iv
  #Get the plotIndividDataAndCurves function from another file
  source('individDataWithPsychometricCurves.R') 
  factorsForPlot <- tibble( colorF = "targets", colF = "objects", rowF = "subject" )
  
  #Problem curvefitting subject= 64  objects= 8  targets= 3. Indeed with targets =2 and objects =8, slope is positive!
  #if length(unique())
  
  datForThisPlot <- datAnalyze |> filter(  as.numeric(as.character(subject)) >= 27 ) |>
        filter(  as.numeric(as.character(subject)) <= 999 )
  psychometricsForThisPlot <- psychometrics |> filter( as.numeric(as.character(subject)) >=27  ) |>
    filter(  as.numeric(as.character(subject)) <= 999 )
  
  plt<- plotIndividDataAndCurves(expName,datForThisPlot,psychometricsForThisPlot,
                           factorsForPlot,wrapOrGrid=T,xmin=0,xmax=1.5) 
  plt<-plt+facet_wrap(vars(subject))
  show(plt)
  ggsave( file.path('figs', paste0('individPlotsE',expName,'.png'))  )
  
  #Psychometric doesn't go high enough with subject= 69  objects= 8  targets= 2, which
  #from the below individual graph looks appropriate - the persom was getting 25% wrong even at low speeds
  sub69<- datAnalyze |> filter( subject==69)
  s69<- plotIndividDataAndCurves("subject69",sub69,
                           psychometricsForThisPlot |> filter(subject==69),
                           tibble( colorF = "targets", colF = "targets", rowF = "objects" ),
                           wrapOrGrid=T,xmin=0,xmax=1.5)
  
  show(s69)

  
  thrAll<-tibble()
  source("extractThreshesAndPlot.R") #provides threshes
  #Add threshes to the plots so that can see where threshold extraction failed
  
  thrAll<-rbind(thrAll,threshes)
  #below is old way, saving separate threshes
  #   varName=paste("threshes_",iv,"_",expName,sep='') #combine threshes
  #   assign(varName,threshes)
  #   save(list=varName,file=paste(dataDir,varName,".Rdata",sep='')) #e.g. threshes_tf_123targets269objects.Rdata
  #   cat("Saved",varName)
}
